{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03eBhLCZl9eT"
      },
      "source": [
        "# Transform pdf to txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZv6e9Qcl9pj"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install pycryptodome\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WGfkGpFl-eq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "search_path = '/content/drive/My Drive/Files'\n",
        "\n",
        "# Get a list of all PDF files in the specified folder\n",
        "pdf_files = [f for f in os.listdir(search_path) if f.endswith('.pdf')]\n",
        "\n",
        "# Loop through each PDF file\n",
        "for filename in pdf_files:\n",
        "    # Extract company name from filename\n",
        "    company_name = os.path.splitext(filename)[0]\n",
        "\n",
        "    # Search for the file\n",
        "    file_path = os.path.join(search_path, filename)\n",
        "\n",
        "    # Open PDF file\n",
        "    with open(file_path, 'rb') as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        num_pages = len(reader.pages)\n",
        "\n",
        "        # Counter for parts and line count\n",
        "        part_counter = 1\n",
        "        line_counter = 0\n",
        "\n",
        "        formatted_text = f\"Source Document: {company_name}\\n\\n\"\n",
        "\n",
        "        # Iterate through each page\n",
        "        for i in range(num_pages):\n",
        "            # Add the section heading to the formatted text\n",
        "            formatted_text += f\"### Section: Page {i + 1}\\n\"\n",
        "            line_counter += 1\n",
        "\n",
        "            # Extract text from the page\n",
        "            text = reader.pages[i].extract_text()\n",
        "\n",
        "            # Split the text into lines and iterate through each line\n",
        "            for line in text.split('\\n'):\n",
        "                formatted_text += line + '\\n'\n",
        "                line_counter += 1\n",
        "\n",
        "                # Check if line counter exceeds n\n",
        "                if line_counter >= 500:\n",
        "                    # Define a function to save text to a file\n",
        "                    def save_to_file(text, part):\n",
        "                        file_name = f\"{company_name} part {part}.txt\"\n",
        "                        file_path = os.path.join(search_path, file_name)\n",
        "                        with open(file_path, 'w', encoding='utf-8') as text_file:\n",
        "                            text_file.write(text)\n",
        "                        print(f\"Text file for {company_name} part {part} saved successfully.\")\n",
        "\n",
        "                    save_to_file(formatted_text, part_counter)\n",
        "                    part_counter += 1\n",
        "                    formatted_text = f\"Source Document: {company_name}\\n\\n\"\n",
        "                    line_counter = 2\n",
        "\n",
        "            # Add a delimiter between sections\n",
        "            formatted_text += '\\n'\n",
        "            line_counter += 1\n",
        "\n",
        "        # Save any remaining text that didn't reach 500 lines\n",
        "        if formatted_text.strip() != f\"Document: {company_name}\":\n",
        "            save_to_file(formatted_text, part_counter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpi0PySs75j7"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDBpX8YlZhea"
      },
      "source": [
        "# Cut text files in smaller in order to reduce tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMvUlBL9QBQo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "search_path = '/content/drive/My Drive/Files'\n",
        "\n",
        "# Get a list of all text files in the specified folder\n",
        "text_files = [f for f in os.listdir(search_path) if f.endswith('.txt')]\n",
        "\n",
        "# Function to save text to a file\n",
        "def save_to_file(text, part, company_name):\n",
        "    file_name = f\"{company_name} part {part}.txt\"\n",
        "    file_path = os.path.join(search_path, file_name)\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(text)\n",
        "    print(f\"Text file for {company_name} part {part} saved successfully.\")\n",
        "\n",
        "# Loop through each text file\n",
        "for filename in text_files:\n",
        "    # Extract file name without extension as company name\n",
        "    company_name = os.path.splitext(filename)[0]\n",
        "\n",
        "    # Search for the file\n",
        "    file_path = os.path.join(search_path, filename)\n",
        "\n",
        "    # Initialize counters\n",
        "    part_counter = 1\n",
        "    line_counter = 0\n",
        "    formatted_text = \"\"\n",
        "\n",
        "    # Open and read the text file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            formatted_text += line\n",
        "            line_counter += 1\n",
        "\n",
        "            # Check if line counter exceeds 100\n",
        "            if line_counter >= 100:\n",
        "                save_to_file(formatted_text, part_counter, company_name)\n",
        "                part_counter += 1\n",
        "                formatted_text = \"\"\n",
        "                line_counter = 0\n",
        "\n",
        "    # Save any remaining text that didn't reach 100 lines\n",
        "    if formatted_text.strip() != \"\":\n",
        "        save_to_file(formatted_text, part_counter, company_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Questions About Document"
      ],
      "metadata": {
        "id": "eYLSh0Kpi66S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "id": "yWe0iq5qg_1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "dgchPUqZiFqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=''\n"
      ],
      "metadata": {
        "id": "PmCuqjv24tp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "W-COmPiE5GrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import dotenv\n",
        "from dotenv import load_dotenv\n",
        "import re  # For regular expressions\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "def generate_questions(text, model=\"gpt-4-0125-preview\"):\n",
        "    \"\"\"\n",
        "    Generates a list of questions based on the provided text using OpenAI's GPT-4 Chat API.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert at creating multiple questions based on materials and documentation. Generate a list of 10 questions from the provided text.\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ]\n",
        "        )\n",
        "        generated_text = response.choices[0].message['content'].strip()\n",
        "        # Split the generated text into individual questions\n",
        "        questions = re.split(r'\\d+\\.\\s+', generated_text)[1:]  # Split and remove the first empty entry if any\n",
        "        return questions\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "directory_path = './drive/My Drive/Files'\n",
        "\n",
        "data = []\n",
        "\n",
        "# Processing each text file in the directory\n",
        "for filename in tqdm(os.listdir(directory_path), desc='Processing files'):\n",
        "    if filename.endswith('.txt'):\n",
        "        file_path = os.path.join(directory_path, filename)\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                text_content = file.read().strip()\n",
        "                generated_questions = generate_questions(text_content)\n",
        "                for question in generated_questions:\n",
        "                    instruction = \"You are a helpful assistant. Answer this question: \" + question.replace('\\n', ' ').strip()\n",
        "                    data.append({'Instruction': instruction, 'Input': text_content})\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred while processing file: {file_path}\\n{e}\")\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "aeJM1hvsIWOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Instruction\"][200]"
      ],
      "metadata": {
        "id": "47TABx8emfpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "XiKRzyNa3X_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "-cIPiP2j65Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "#convert dataset into dataframe to be able to push\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "dataset.push_to_hub(\"AnonymousAuthorICAIF24/Instruction_Input_dataset_08_04\")"
      ],
      "metadata": {
        "id": "LkipJkJi6UDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Answers and Create Training Dataset"
      ],
      "metadata": {
        "id": "dUVRpmiT-T_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "id": "cVq-JM-J-mph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "NKoB3QrzE43_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = ''"
      ],
      "metadata": {
        "id": "X14fuXmu-0IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import openai\n",
        "\n",
        "# Load the dataset from Hugging Face\n",
        "dataset_name = 'AnonymousAuthorICAIF24/Instruction_Input_dataset_08_04'\n",
        "dataset = load_dataset(dataset_name)\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Define the function to generate text\n",
        "def generate_text(prompt, model=\"gpt-4-0125-preview\"):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides detailed, clear, and accurate answers.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        # Log the error for debugging\n",
        "        print(f\"An error occurred with prompt: {prompt}\\nError: {e}\")\n",
        "        return \"Error generating response.\"\n",
        "\n",
        "# Placeholder for answers\n",
        "answers = []\n",
        "\n",
        "# Iterate over each row in the DataFrame and generate text\n",
        "for index, row in df.iterrows():\n",
        "    prompt = f\"Please provide a detailed, clear, and accurate answer for this question based on the text: \\\"{row['Input']}\\\". Question: {row['Instruction']}\"\n",
        "    generated_text = generate_text(prompt, model=\"gpt-4-0125-preview\")  # Switch model if needed\n",
        "    answers.append(generated_text)\n",
        "\n",
        "# Update the DataFrame with the generated answers\n",
        "df['Output'] = answers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UqQAf5I0-S3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Output'][200]"
      ],
      "metadata": {
        "id": "2sji-NJ3-eL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Y8O4sVq6FA8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "_PjNUe1-xM1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "#convert dataset into dataframe to be able to push\n",
        "dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "jcekvjQexSqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.push_to_hub(\"AnonymousAuthorICAIF24/GPT-QA-V2_08_04\")"
      ],
      "metadata": {
        "id": "vUIKt5AGxT4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset for training the model"
      ],
      "metadata": {
        "id": "VWWayU56RDPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers trl accelerate torch bitsandbytes peft datasets -qU\n",
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "WfbkoVA65nOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "5Yh26RaqVoqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"AnonymousAuthorICAIF24/GPT-QA-V2_08_04\", split=\"train\")\n",
        "dataset\n",
        "df = dataset.to_pandas()\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "oLw3r5ppRLjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(data_point):\n",
        "    \"\"\"Gen. input text based on a prompt, task instruction, (context info.), and answer:param data_point: dict: Data point\n",
        "    :return: dict: tokenzed prompt\n",
        "    \"\"\"\n",
        "    prefix_text = 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\\\n\\\\n'\n",
        "    # Samples with additional context into.\n",
        "    if data_point['Input']:\n",
        "        text = f\"\"\"<s>[INST]{prefix_text} {data_point[\"Instruction\"]} Base the answer according to the text:  {data_point[\"Input\"]} [/INST]</s> \\\\\\\\n <s>{data_point[\"Output\"]}</s>\"\"\"\n",
        "    # Without\n",
        "    else:\n",
        "        text = f\"\"\"<s>[INST]{prefix_text} {data_point[\"Instruction\"]} [/INST] </s> \\\\\\\\n <s> {data_point[\"Output\"]} </s>\"\"\"\n",
        "    return text\n",
        "# add the \"prompt\" column in the dataset\n",
        "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
        "dataset = dataset.add_column(\"prompt\", text_column)"
      ],
      "metadata": {
        "id": "GIA_E8oZ5Eja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aG40bPKT7DoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"prompt\"][1]"
      ],
      "metadata": {
        "id": "d6jS_igFWW75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "zsGMX_GZ6vTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(seed=1234)  # Shuffle dataset here\n",
        "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)"
      ],
      "metadata": {
        "id": "oZTUMD1U5eqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset[\"train\"]"
      ],
      "metadata": {
        "id": "9jXcfDBx50VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Mistral 7B Instruct 2\n"
      ],
      "metadata": {
        "id": "tdM1_DqAPI7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base model from huggingFace or path to model\n",
        "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "new_model = \"Fine-Tuned_Mistral-Instruct-V2_06-05\"\n",
        "\n",
        "dataset_name =\"AnonymousAuthorICAIF24/GPT-QA-V2_08_04\""
      ],
      "metadata": {
        "id": "fcpqmMZTPM7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U bitsandbytes\n",
        "!pip install transformers==4.36.2\n",
        "!pip install -U peft\n",
        "!pip install -U accelerate\n",
        "!pip install -U trl\n",
        "!pip install datasets==2.16.0\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "nSn1pTVVPM0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import re\n"
      ],
      "metadata": {
        "id": "j5a5fSBlPMvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login #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\n",
        "login()"
      ],
      "metadata": {
        "id": "L9iiBFQ2PMpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split=\"train\")\n",
        "dataset\n",
        "df = dataset.to_pandas()\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "J-gGSApR7RuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit= True,\n",
        "    bnb_4bit_quant_type= \"nf4\",\n",
        "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant= False,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model,\n",
        "        load_in_4bit=True,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        ")\n",
        "\n",
        "\n",
        "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
        "model.config.pretraining_tp = 1\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_eos_token = True\n",
        "tokenizer.bos_token, tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "y24cu7cGPMfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(data_point):\n",
        "\n",
        "    text = f\"\"\"<s>[INST] {data_point[\"Instruction\"]} [/INST] </s> \\\\\\\\n <s> {data_point[\"Output\"]} </s>\"\"\"\n",
        "\n",
        "    return text\n",
        "# add the \"prompt\" column in the dataset\n",
        "text_column = [generate_prompt(data_point) for data_point in dataset]\n",
        "dataset = dataset.add_column(\"prompt\", text_column)"
      ],
      "metadata": {
        "id": "5CfRBH8N7eyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(seed=1234)  # Shuffle dataset here\n",
        "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)"
      ],
      "metadata": {
        "id": "f6q1sRSG7hHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset"
      ],
      "metadata": {
        "id": "OUx0nWSu7g17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "p5RMmm667pQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "jy-TfIen76s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count training tokens\n",
        "from transformers import LlamaTokenizer\n",
        "tokenizer_ = LlamaTokenizer.from_pretrained(base_model)\n",
        "tokens = tokenizer_.tokenize(train_data.to_pandas().to_string())\n",
        "len(tokens)"
      ],
      "metadata": {
        "id": "pOGA7nRePMWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding the adapters in the layers\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
        ")\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "WgISaiMbPMQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparamter\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=50,\n",
        "    logging_steps=1,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "rqoG33WIPMK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting sft parameters\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= None,\n",
        "    dataset_text_field=\"prompt\",\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        ")"
      ],
      "metadata": {
        "id": "1uayijwMPMF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PYTORCH_NO_CUDA_MEMORY_CACHING=1"
      ],
      "metadata": {
        "id": "17Jm6nXjTvk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "kfmDbS6TPMAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model (the adapter)\n",
        "trainer.model.save_pretrained(new_model)\n",
        "model.config.use_cache = True\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "6-xX-m8HPL7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.push_to_hub(new_model)"
      ],
      "metadata": {
        "id": "ZHX5vnjlQTmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model"
      ],
      "metadata": {
        "id": "6DSkRyPKvMCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U bitsandbytes\n",
        "!pip install transformers==4.36.2\n",
        "!pip install -U peft\n",
        "!pip install -U accelerate\n",
        "!pip install -U trl\n",
        "!pip install datasets==2.16.0\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "O1UcCasfvqzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import re\n"
      ],
      "metadata": {
        "id": "qNV_xCKFvvZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "oR7tJX8rxgdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "new_model = \"AnonymousAuthorICAIF24/Fine-Tuned_Mistral-Instruct-V2_06-05\"\n",
        "\n",
        "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        return_dict=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model_reload, new_model)\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "tXP7ys8FZ6bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.set_verbosity(logging.CRITICAL)\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=2000)"
      ],
      "metadata": {
        "id": "FNqnJdYzZ7dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt(question):\n",
        "  prompt=f\"<s>[INST] You are a helpful assistant. Make direct answers with good explanations. Do not lie and if you do not know the answer, say you do not know. Answer this question: {question} [/INST]\"\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "akG5vRdyJw1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the five credit rating levels that can be assigned for tied assets? Explain each level.\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "N6HkzwR7VPcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the primary investment principles for total assets?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "Hh2BZvA20Quh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the rules for investment in cash deposits?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "TpefZ7WfHXME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How are bonds and convertible bonds treated?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "tMfnswn-HZjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What specific limits are placed on investments in foreign currencies?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "SKlYFpjeHe2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are high-risk investments for insurance companies?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "aKBdXvdpHgta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How are investments in high-risk assets regulated?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "lPxR7YtP0-iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the consequences for failing to comply with the guidelines?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "GNRMJpGuHkB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How should claims of non-life insurers against reinsurers be handled?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "MumG-av4Hlf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the protocol for the inclusion of new types of investments?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "rKT19bvzmq1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the principle of diversification within tied assets?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "dfjxocLOHpCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What limits are set for investments in equities and equity securities?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "MApANHeomqf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the specific limitations for investing in real estate within tied assets?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "ym7oPGqDmqUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are synthetic bonds and how are they used?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "xmolUQSNmqJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How should insurance companies manage and report structured product investments?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "_ZqlsFC4HuTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What derivatives can be used to hedge credit risk of asset portfolio?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "OwEKBotqmspL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How should liquidity be maintained when using derivatives in investment strategies?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "dA9aHsrwnmZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What specific provisions must be followed when dealing with tied assets in relation to unit-linked life insurance policies?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "LoixfSJyMPuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Explain the criteria and process for allocating an investment to tied assets.\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "pYog2S_vMQNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How are claims of non-life insurers against reinsurers treated in the context of tied assets?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "WHCqCd9AMQ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the limitations and conditions for credit exposure to counterparties within tied assets?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "2c4UATG_MyVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How are mortgage receivables treated under the tied assets regulations?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "JBWICNH4Mx_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How do regulations ensure that the claims of the insured are prioritized in the event of an insurer's insolvency?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "3gvnZBW7Mxyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the penalties for violating the tied asset regulations?\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "wzhv-6sjMxl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Describe the process for the annual evaluation of the insurance company's overall investment portfolio including tied assets.\"\n",
        "prompt = build_prompt(question)\n",
        "result = pipe(prompt)\n",
        "\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "u8nInuXeNhP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Implementation\n"
      ],
      "metadata": {
        "id": "WM3ZxAGoeLiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "dFekRwzpzBZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n",
        "!pip install python-dotenv\n",
        "!pip -q install git+https://github.com/huggingface/transformers\n",
        "!pip install -q datasets loralib sentencepiece\n",
        "!pip install -q einops accelerate langchain bitsandbytes\n",
        "!pip install sentence_transformers\n",
        "!pip install llama-index\n",
        "%pip install llama-index-llms-huggingface"
      ],
      "metadata": {
        "id": "9p8A5bEqzBKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes\n",
        "!pip install -U peft"
      ],
      "metadata": {
        "id": "T8b1ZlC859J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index-embeddings-langchain\n",
        "%pip install -U langchain-community"
      ],
      "metadata": {
        "id": "GgqaW3NU6Iix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model"
      ],
      "metadata": {
        "id": "8KnUcv5U5JyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "R6LL-Pgl5JsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./drive/My Drive/Files\").load_data()\n"
      ],
      "metadata": {
        "id": "rfN7vSKs5Je_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "S3_w0-x9Oj_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "system_prompt = \"You are a helpful assistant. Make direct answers with good explanations. Do not lie and if you do not know the answer, say you do not know. Answer this question:\"\n",
        "# This will wrap the default prompts that are internal to llama-index\n",
        "query_wrapper_prompt = \"<|USER|>{query_str}<|ASSISTANT|>\""
      ],
      "metadata": {
        "id": "qetjD6YlElUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "Nwpd8a7E5YmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.set_default_device('cuda')"
      ],
      "metadata": {
        "id": "VIygjaEr5Yb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PYTORCH_NO_CUDA_MEMORY_CACHING=1"
      ],
      "metadata": {
        "id": "z7hYhBy85YUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "adapter = \"AnonymousAuthorICAIF24/Fine-Tuned_Mistral-Instruct-V2_06-05\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map={\"\": 0}, torch_dtype=torch.bfloat16)\n",
        "model = PeftModel.from_pretrained(model, adapter)"
      ],
      "metadata": {
        "id": "bZyldiMi5YEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "7DXaZuUK6Dn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=2048,\n",
        "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": True},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    device_map=\"auto\",\n",
        "    tokenizer_kwargs={\"max_length\": 4096},\n",
        "    model_kwargs={\"torch_dtype\": torch.float16}\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "u3qYOpnF6FT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")"
      ],
      "metadata": {
        "id": "K75q-pty6MjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "3GRLyAki6P4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "89buk7gW6RkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the five credit rating levels that can be assigned for tied assets? Explain each level.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "9eAOnYL56TVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the primary investment principles for total assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "SM_4ObDtKMZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the rules for investment in cash deposits?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "y29Y5REv9LtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are bonds and convertible bonds treated?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7nGLtKoR9LZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What specific limits are placed on investments in foreign currencies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "kGUU5y9Q9K2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are high-risk investments for insurance companies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "7DW5yB5U9Udg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are investments in high-risk assets regulated?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "qvNbNLCBAKJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the consequences for failing to comply with the guidelines?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "mTOOq3pImUu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How should claims of non-life insurers against reinsurers be handled?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "KrHLVMVbmXPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the protocol for the inclusion of new types of investments?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "VrEgZUbDmAPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the principle of diversification within tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "ZaByny9tmAA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What limits are set for investments in equities and equity securities?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "lkVO2XUTl_yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the specific limitations for investing in real estate within tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "HJLhblVAl_ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are synthetic bonds and how are they used?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "h5mG7EHWAwEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How should insurance companies manage and report structured product investments?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "JT-VFujVAxx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What derivatives can be used to hedge credit risk of asset portfolio?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "yJ2iKLxWAyRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How should liquidity be maintained when using derivatives in investment strategies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "VAGPlMzVKwGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What specific provisions must be followed when dealing with tied assets in relation to unit-linked life insurance policies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "2u6R2ZMwA7Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Explain the criteria and process for allocating an investment to tied assets.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "8Fs_yeApA7C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are claims of non-life insurers against reinsurers treated in the context of tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "SEN0mJRlA6zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the limitations and conditions for credit exposure to counterparties within tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "teC9wj07BJGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are mortgage receivables treated under the tied assets regulations?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "s52XpA1tBI5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How do regulations ensure that the claims of the insured are prioritized in the event of an insurer's insolvency?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "2cQMVyCMBIrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the penalties for violating the tied asset regulations?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "iwISMsEmBIdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Describe the process for the annual evaluation of the insurance company's overall investment portfolio including tied assets.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "zdJ5d1uhBIQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answers Untrained Model:"
      ],
      "metadata": {
        "id": "UlX9pZIRjvk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=2048,\n",
        "    generate_kwargs={\"temperature\": 0.1, \"do_sample\": True},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    device_map=\"auto\",\n",
        "    tokenizer_kwargs={\"max_length\": 4096},\n",
        "    model_kwargs={\"torch_dtype\": torch.float16}\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "gucl15oAjuQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model"
      ],
      "metadata": {
        "id": "69Idj8vshnH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "\n",
        "\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        ")"
      ],
      "metadata": {
        "id": "Ju2h_eYqX1Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "ewlajF63kCci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "rdw2dbtJ2Czz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "AoOwXpqhpfzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the five credit rating levels that can be assigned for tied assets? Explain each level.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1bLpfxbpkFC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the primary investment principles for total assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "5VVRHbMr9V7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the rules for investment in cash deposits?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1wZ4XvgH9V4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are bonds and convertible bonds treated?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "FQL9jusS9V2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What specific limits are placed on investments in foreign currencies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "4ltU4OJF9VxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are high-risk investments for insurance companies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Sh9U0Icv9Vp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are investments in high-risk assets regulated?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "ex-IMHtdoSgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the consequences for failing to comply with the guidelines?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "56ICfn7Qi241"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How should claims of non-life insurers against reinsurers be handled?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "bjmyEmlci3Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the protocol for the inclusion of new types of investments?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "lgcYRlwui4NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the principle of diversification within tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "l4DMnsEBi41U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What limits are set for investments in equities and equity securities?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "V_vPRXg-i4Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the specific limitations for investing in real estate within tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "vqvT9F8Vi6TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are synthetic bonds and how are they used?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "TzJIRsLmCLVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How should insurance companies manage and report structured product investments?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "UN-CTuIZCP8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What derivatives can be used to hedge credit risk of asset portfolio?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "2eLTudRJCPXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How should liquidity be maintained when using derivatives in investment strategies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "8dNkYCm3CO1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What specific provisions must be followed when dealing with tied assets in relation to unit-linked life insurance policies?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "60pYuLI2COOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Explain the criteria and process for allocating an investment to tied assets.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "O3x_FzoMCNa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are claims of non-life insurers against reinsurers treated in the context of tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "lTcDk-S2CMrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the limitations and conditions for credit exposure to counterparties within tied assets?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "dnf7MIqLCsmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are mortgage receivables treated under the tied assets regulations?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "K828Cc-BCsDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How do regulations ensure that the claims of the insured are prioritized in the event of an insurer's insolvency?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "_2qvl_TACr6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are the penalties for violating the tied asset regulations?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "NUQoyxwsCrkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Describe the process for the annual evaluation of the insurance company's overall investment portfolio including tied assets.\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "2J3s44OhCrUm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "03eBhLCZl9eT",
        "aDBpX8YlZhea",
        "Wv0jrJs0NuUZ",
        "6qnOBMb7bq3J",
        "eYLSh0Kpi66S",
        "tPndnq-ofWlu",
        "g8i0Cq9EprVc",
        "dUVRpmiT-T_z",
        "iJeGDbeZAD9D",
        "VWWayU56RDPw",
        "tdM1_DqAPI7k",
        "6DSkRyPKvMCM"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}